<!DOCTYPE html>
<html lang="ko">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MaLangEE Realtime Test</title>
    <style>
        body {
            font-family: sans-serif;
            padding: 20px;
            text-align: center;
        }

        button {
            padding: 10px 20px;
            font-size: 16px;
            margin: 10px;
            cursor: pointer;
        }

        #status {
            margin-top: 20px;
            font-weight: bold;
            color: gray;
        }

        #log {
            margin-top: 20px;
            text-align: left;
            max-height: 300px;
            overflow-y: auto;
            border: 1px solid #ccc;
            padding: 10px;
        }
    </style>
</head>

<body>
    <h1>MaLangEE Realtime Test</h1>
    <button id="connectBtn">Connect & Start</button>
    <button id="disconnectBtn" disabled>Disconnect</button>
    <div id="status">Disconnected</div>
    <div id="log"></div>

    <script>
        let ws;
        let audioContext;
        let mediaStream;
        let workletNode;
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const statusDiv = document.getElementById('status');
        const logDiv = document.getElementById('log');

        function log(msg) {
            logDiv.innerHTML += `<div>${msg}</div>`;
            logDiv.scrollTop = logDiv.scrollHeight;
        }

        connectBtn.onclick = async () => {
            statusDiv.textContent = "Connecting...";
            // 1. WebSocket Connect
            ws = new WebSocket("ws://localhost:8002/ws/chat");

            ws.onopen = async () => {
                statusDiv.textContent = "Connected. Initializing Audio...";
                log("WS Connected");
                connectBtn.disabled = true;
                disconnectBtn.disabled = false;
                await startAudio();
            };

            ws.onmessage = async (event) => {
                const data = JSON.parse(event.data);
                if (data.type === "audio.delta") {
                    // Play Received Audio (Base64 -> PCM16 -> AudioBuffer)
                    playPcm16(data.delta);
                } else if (data.type === "speech.started") {
                    log("User started speaking... (Interruption detected)");
                    // Cancel current audio playback (Barge-in)
                    clearScheduledAudio();
                } else if (data.type === "transcript.done") {
                    log(`AI: ${data.transcript}`);
                } else if (data.type === "user.transcript") {
                    log(`You: ${data.transcript}`);
                }
            };

            ws.onclose = () => {
                statusDiv.textContent = "Disconnected";
                connectBtn.disabled = false;
                disconnectBtn.disabled = true;
                stopAudio();
                log("WS Closed");
            };
        };

        disconnectBtn.onclick = () => {
            if (ws) ws.close();
        };

        async function startAudio() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 24000,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });

                log("Microphone Access Granted");

                // Initialize AudioWorklet for raw PCM processing
                await audioContext.audioWorklet.addModule("data:text/javascript;base64," + btoa(`
                    class Processor extends AudioWorkletProcessor {
                        process(inputs, outputs, parameters) {
                            const input = inputs[0];
                            if (input.length > 0) {
                                const float32Data = input[0];
                                const int16Data = new Int16Array(float32Data.length);
                                for (let i = 0; i < float32Data.length; i++) {
                                    // Float32 (-1.0 to 1.0) -> Int16 (-32768 to 32767)
                                    let s = Math.max(-1, Math.min(1, float32Data[i]));
                                    int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                                }
                                this.port.postMessage(int16Data.buffer);
                            }
                            return true;
                        }
                    }
                    registerProcessor('recorder-processor', Processor);
                `));

                const source = audioContext.createMediaStreamSource(mediaStream);
                workletNode = new AudioWorkletNode(audioContext, 'recorder-processor');

                workletNode.port.onmessage = (event) => {
                    // PCM16 ArrayBuffer
                    const arrayBuffer = event.data;
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        // Convert ArrayBuffer to Base64
                        const base64Audio = arrayBufferToBase64(arrayBuffer);
                        ws.send(JSON.stringify({
                            type: "input_audio_buffer.append",
                            audio: base64Audio
                        }));
                    }
                };

                source.connect(workletNode);
                workletNode.connect(audioContext.destination);
                // Mute local feedback? No, destination needed for worklet to run in some browsers.
                // However, to avoid self-hearing, we can disconnect or set gain to 0. 
                // For now, let's keep it connected but be aware of feedback if speakers are loud.
                // Actually, let's disconnect to be safe.
                workletNode.disconnect();

            } catch (e) {
                log(`Error starting audio: ${e.message}`);
            }
        }

        function stopAudio() {
            if (mediaStream) mediaStream.getTracks().forEach(track => track.stop());
            if (audioContext) audioContext.close();
        }

        let nextStartTime = 0;
        let scheduledAudioSources = [];

        function playPcm16(base64Data) {
            if (!audioContext) return;

            const binaryString = atob(base64Data);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            const int16Data = new Int16Array(bytes.buffer);
            const float32Data = new Float32Array(int16Data.length);

            for (let i = 0; i < int16Data.length; i++) {
                float32Data[i] = int16Data[i] / 32768.0;
            }

            const buffer = audioContext.createBuffer(1, float32Data.length, 24000);
            buffer.getChannelData(0).set(float32Data);

            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.connect(audioContext.destination);

            // Audio Scheduling Logic
            const currentTime = audioContext.currentTime;

            // If nextStartTime is in the past (gap in audio), reset to now
            if (nextStartTime < currentTime) {
                nextStartTime = currentTime;
            }

            source.start(nextStartTime);

            // Track source for cancellation
            scheduledAudioSources.push(source);
            source.onended = () => {
                const index = scheduledAudioSources.indexOf(source);
                if (index > -1) scheduledAudioSources.splice(index, 1);
            };

            // Increment next start time by duration of this chunk
            nextStartTime += buffer.duration;
        }

        function clearScheduledAudio() {
            log("Interruption: Stopping audio...");
            scheduledAudioSources.forEach(source => {
                try { source.stop(); } catch (e) { }
            });
            scheduledAudioSources = [];
            // Reset timing so next response starts fresh
            if (audioContext) {
                nextStartTime = audioContext.currentTime;
            }
        }

        function arrayBufferToBase64(buffer) {
            let binary = '';
            const bytes = new Uint8Array(buffer);
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }
    </script>
</body>

</html>