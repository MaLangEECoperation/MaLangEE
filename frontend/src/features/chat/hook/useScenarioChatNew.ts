"use client";

import { useState, useCallback, useRef } from "react";
import { tokenStorage } from "@/features/auth";
import { translateToKorean } from "@/shared/lib/translate";
import { useWebSocketBase } from "./useWebSocketBase";

export interface ScenarioChatStateNew {
  isConnected: boolean;
  isReady: boolean;
  logs: string[];
  aiMessage: string;
  aiMessageKR: string;
  userTranscript: string;
  isAiSpeaking: boolean;
  isRecording: boolean;
  scenarioResult: any | null;
}

export function useScenarioChatNew() {
  // ì‹œë‚˜ë¦¬ì˜¤ íŠ¹í™” ìƒíƒœ
  const [aiMessage, setAiMessage] = useState("");
  const [aiMessageKR, setAiMessageKR] = useState("");
  const [userTranscript, setUserTranscript] = useState("");
  const [scenarioResult, setScenarioResult] = useState<any | null>(null);

  // WebSocket URL ìƒì„±
  const getWebSocketUrl = useCallback(() => {
    const token = tokenStorage.get();
    const envWsUrl = process.env.NEXT_PUBLIC_WS_URL;
    let wsBaseUrl = envWsUrl;

    console.log("ğŸ”§ [DEBUG] Token:", token ? "EXISTS" : "NONE");
    console.log("ğŸ”§ [DEBUG] NEXT_PUBLIC_WS_URL:", envWsUrl);

    if (!wsBaseUrl && process.env.NEXT_PUBLIC_API_URL) {
      const apiUrl = process.env.NEXT_PUBLIC_API_URL;
      wsBaseUrl = apiUrl.replace(/^http/, "ws");
      if (window.location.protocol === "https:" && wsBaseUrl.startsWith("ws:")) {
        wsBaseUrl = wsBaseUrl.replace(/^ws:/, "wss:");
      }
      console.log("ğŸ”§ [DEBUG] wsBaseUrl from API_URL:", wsBaseUrl);
    }

    if (!wsBaseUrl) {
      const protocol = window.location.protocol === "https:" ? "wss" : "ws";
      const host = window.location.hostname;
      const port = window.location.port ? `:${window.location.port}` : "";
      wsBaseUrl = `${protocol}://${host}${port}`;
      console.log("ğŸ”§ [DEBUG] wsBaseUrl from location:", wsBaseUrl);
    }

    const endpoint = token ? "/api/v1/scenarios/ws/scenario" : "/api/v1/scenarios/ws/guest-scenario";
    const params = new URLSearchParams();
    if (token) params.append("token", token);

    const queryString = params.toString();
    const finalUrl = queryString ? `${wsBaseUrl}${endpoint}?${queryString}` : `${wsBaseUrl}${endpoint}`;
    console.log("ğŸ”§ [DEBUG] Final WebSocket URL:", finalUrl);

    return finalUrl;
  }, []);

  // onMessage ì½œë°±ì„ refë¡œ ê´€ë¦¬
  const onMessageRef = useRef<((event: MessageEvent) => void) | undefined>(undefined);

  // useWebSocketBase ì‚¬ìš©
  const base = useWebSocketBase({
    getWebSocketUrl,
    onMessage: useCallback((event: MessageEvent) => {
      onMessageRef.current?.(event);
    }, []),
    autoConnect: false,
  });

  // ì„¸ì…˜ ì´ˆê¸°í™” í•¨ìˆ˜ë¥¼ refë¡œ ê´€ë¦¬í•˜ì—¬ ìˆœí™˜ ì°¸ì¡° ë°©ì§€
  const startScenarioSessionRef = useRef<(() => void) | null>(null);

  // onMessage êµ¬í˜„ (baseë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì—¬ê¸°ì„œ ì •ì˜)
  onMessageRef.current = (event: MessageEvent) => {
    try {
      const data = JSON.parse(event.data);

      switch (data.type) {
        case "ready":
          base.addLog("âœ… Received 'ready'. Scenario session initialized.");
          base.addLog("â„¹ï¸ Automatically starting scenario session...");
          base.setIsReady(true);
          // ready ìˆ˜ì‹  ì¦‰ì‹œ ì„¸ì…˜ ì´ˆê¸°í™”
          if (startScenarioSessionRef.current) {
            startScenarioSessionRef.current();
          }
          break;

        case "response.audio.delta":
          base.playAudioChunk(data.delta, data.sample_rate || 24000);
          break;

        case "response.audio.done":
          base.addLog("AI audio stream completed");
          break;

        case "response.audio_transcript.delta":
          if (data.transcript_delta) {
            setAiMessage(prev => prev + data.transcript_delta);
            base.addLog(`AI (delta): ${data.transcript_delta}`);
          }
          break;

        case "response.audio_transcript.done":
          setAiMessage(data.transcript);
          base.addLog(`AI: ${data.transcript}`);
          translateToKorean(data.transcript).then(translated => {
            setAiMessageKR(translated);
            base.addLog(`AI (KR): ${translated}`);
          });
          break;

        case "speech.started":
          base.addLog("User speech started (VAD)");
          base.stopAudio();
          base.setIsUserSpeaking(true);
          break;

        case "input_audio.transcript":
          if (data.transcript) {
            setUserTranscript(data.transcript);
            base.setIsUserSpeaking(false);
            base.addLog(`User: ${data.transcript}`);
          }
          break;

        case "scenario.completed":
          base.addLog(`âœ… Scenario Completed: ${JSON.stringify(data.json)}`);
          base.addLog("â„¹ï¸ Scenario has been automatically saved to the database.");
          setScenarioResult({
            place: data.json?.place || null,
            conversation_partner: data.json?.conversation_partner || null,
            conversation_goal: data.json?.conversation_goal || null,
            sessionId: data.json?.sessionId,
          });
          break;

        case "error":
          base.addLog(`Error: ${data.message}`);
          break;
      }
    } catch (e) {
      base.addLog(`Parse Error: ${e}`);
    }
  };

  // ì˜¤ë””ì˜¤ ì „ì†¡ ì½œë°± (Scenario ë©”ì‹œì§€ íƒ€ì… ì‚¬ìš©)
  const sendAudioCallback = useCallback((audioData: Float32Array) => {
    if (base.wsRef.current?.readyState === WebSocket.OPEN) {
      const base64 = base.encodeAudio(audioData);
      base.wsRef.current.send(JSON.stringify({
        type: "input_audio_chunk",
        audio: base64,
        sample_rate: 24000
      }));
    }
  }, [base.wsRef, base.encodeAudio]);

  // ë§ˆì´í¬ ì‹œì‘ (baseì˜ startMicrophone + sendAudioCallback)
  const startMicrophone = useCallback(() => {
    return base.startMicrophone(sendAudioCallback);
  }, [base.startMicrophone, sendAudioCallback]);

  // í…ìŠ¤íŠ¸ ì „ì†¡
  const sendText = useCallback((text: string) => {
    if (base.wsRef.current?.readyState === WebSocket.OPEN) {
      base.wsRef.current.send(JSON.stringify({ type: "text", text }));
      base.addLog(`Sent Text: ${text}`);
    }
  }, [base.wsRef, base.addLog]);

  // ì˜¤ë””ì˜¤ ë²„í¼ ì´ˆê¸°í™”
  const clearAudioBuffer = useCallback(() => {
    if (base.wsRef.current?.readyState === WebSocket.OPEN) {
      base.wsRef.current.send(JSON.stringify({ type: "input_audio_clear" }));
      base.addLog("Sent input_audio_clear");
    }
  }, [base.wsRef, base.addLog]);

  // ì˜¤ë””ì˜¤ ì»¤ë°‹
  const commitAudio = useCallback(() => {
    if (base.wsRef.current?.readyState === WebSocket.OPEN) {
      base.wsRef.current.send(JSON.stringify({ type: "input_audio_commit" }));
      base.addLog("Sent input_audio_commit");
    }
  }, [base.wsRef, base.addLog]);

  // ì‹œë‚˜ë¦¬ì˜¤ ì„¸ì…˜ ì´ˆê¸°í™” ë° ëŒ€í™” ì‹œì‘
  const startScenarioSession = useCallback(() => {
    if (base.wsRef.current?.readyState === WebSocket.OPEN && base.isReady) {
      // ì´ˆê¸° ì„¤ì • - turn_detectionì„ í™œì„±í™”í•´ì•¼ ë§ˆì´í¬ê°€ ì‘ë™í•¨
      base.wsRef.current.send(JSON.stringify({
        type: "session.update",
        session: {
          //instructions: "You are a scenario selector. Ask the user what situation they want to practice. Keep it brief and friendly.",
          turn_detection: { type: "server_vad", threshold: 0.5, prefix_padding_ms: 300, silence_duration_ms: 1000 }
        }
      }));
      base.addLog("Sent session.update");

      // AI ë°œí™” ìš”ì²­ (AIê°€ ë¨¼ì € ì¸ì‚¬)
      base.wsRef.current.send(JSON.stringify({
        type: "response.create",
        response: {
          modalities: ["text", "audio"],
         // instructions: "Greet the user and ask what kind of situation they want to practice."
        }
      }));
      base.addLog("Sent response.create");
    }
  }, [base.wsRef, base.isReady, base.addLog]);

  // refì— í•¨ìˆ˜ í• ë‹¹
  startScenarioSessionRef.current = startScenarioSession;

  return {
    state: {
      isConnected: base.isConnected,
      isReady: base.isReady,
      logs: base.logs,
      aiMessage,
      aiMessageKR,
      userTranscript,
      isAiSpeaking: base.isAiSpeaking,
      isRecording: base.isRecording,
      scenarioResult,
    },
    connect: base.connect,
    disconnect: base.disconnect,
    initAudio: base.initAudio,
    startMicrophone,
    stopMicrophone: base.stopMicrophone,
    sendText,
    toggleMute: base.toggleMute,
    clearAudioBuffer,
    commitAudio,
    startScenarioSession,
  };
}
